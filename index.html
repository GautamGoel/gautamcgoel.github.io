<head>
   <style>
	   
     a:link {
	  color: green;
	  background-color: transparent;
	  text-decoration: none;
     }

     a:visited {
	  color: pink;
	  background-color: transparent;
	  text-decoration: none;
     }
	   
      td {
         font-family: verdana;
         font-size: 100%
         padding-top:20px;
	 padding-bottom:20px;
	 padding-right:20px;  
      }

   </style>

</head>

<body>
<br><br>

<table width = "1800" align= "center" style = "border: 0px solid #666; padding-right:35px; border-bottom: 0px">
      <tr>
	      
	<td  width="50%" valign="top"> 
            <br>
            <dd><h2><b> Gautam Goel </b></h2></dd>
            <dd> Simons Institute for the Theory of Computing </dd>
            <dd> University of California at Berkeley </dd>
            <br>
            <dd> <b> Email: </b> ggoel@caltech.edu </dd>
		    
	<td width="50%" valign="top">
	    <br>
            <img width="600px" src="./IMG_7171.JPG" align="right">
	</td>
      </tr>
		
</table>
<table width = "1800" align="center" style = "border: 0px solid #666; padding-right:35px; border-top: 0px">

	<tr> 
	<td>
	    <br>
            <dd style= "text-align: justify"> I am a postdoc at the Simons Institute at UC Berkeley, where I am part of the the Foundations of Data Science Institute (FODSI). Before moving to Berkeley I was a PhD student in the Computing and Mathematical Sciences (CMS) department at Caltech, where I was extremely fortunate to be advised by Babak Hassibi. I am broadly interested in machine learning, optimization, and control, especially 1) online optimization and sequential decision-making under uncertainty, and 2) integrating machine learning with dynamics and control. </dd>
	    <br>	
	    <dd style= "text-align: justify"> My PhD work was supported by a National Science Foundation Graduate Research Fellowship and an Amazon AI4Science Fellowship. My thesis was awarded the Bhansali Family Doctoral Prize in Computer Science, which is awarded by the CMS department to a single outstanding dissertation in computer science each year. </dd>
            <br>		
	    <dd> <b> For more information, please see my <a href="./CV_2021.pdf" > CV. </a> </b> </dd>
         </td>
      </tr>
</table>

<table width = "1800" align = "center" style = "border: 0px solid #666; padding-right:75px; border-top: 0px">
      <tr>
         <td>
            <br>
	    <br>
            <b> Papers. </b> Sorted in decreasing chronological order.
		 <ol>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/2110.12544"> Online estimation and control with optimal pathlength regret</a></b> with Babak Hassibi.</b> L4DC 2022. </li>
		        <br>
		        <li> <b> <a href="https://arxiv.org/abs/2107.13657"> Competitive Control</a></b> with Babak Hassibi.  Transactions of Automatic Control. </li>
	                <br>
	                <li> <b> <a href="https://arxiv.org/abs/2002.02574"> The Power of Linear Controllers in LQR Control</a></b> with Babak Hassibi. CDC 2022. </li>
	                <br>
			<li> <b> <a href="https://arxiv.org/abs/2106.12097"> Regret-Optimal Estimation and Control</a></b> with Babak Hassibi. Transactions of Automatic Control <b> (Special Issue on Learning and Control). </b> </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/2105.01244"> Regret-Optimal Full-Information Control</a> </b> with Oron Sabag, Sahin Lale, and Babak Hassibi. ACC 2021. </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/2011.12785"> Regret-Optimal Measurement-Feedback Control</a></b> with Babak Hassibi. L4DC 2021. </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/1911.03827"> Online Optimization with Predictions and Non-convex Losses</a></b> with Yiheng Lin and Adam Wierman. Sigmetrics 2020. </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/1905.12776"> Beyond Online Balanced Descent: An Optimal Algorithm for Smoothed Online Optimization</a></b> with Yiheng Lin. Haoyuan Sun, and Adam Wierman. NeurIPS 2019 <b> (Spotlight Presentation).</b> </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/1810.10132"> An Online Algorithm for Smoothed Regression and LQR Control</a></b> with Adam Wierman. AISTATS 2019. </li>
			<br>
			<li> <b> <a href="https://arxiv.org/abs/1803.10366"> Smoothed Online Convex Optimization in High Dimensions via Online Balanced Descent</a></b> with Niangjun Chen and Adam Wierman. COLT 2018. </li>
			<br>		  
		        <li> <b> <a href="https://arxiv.org/abs/1704.07785"> Thinking Fast and Slow: Optimization Decomposition across Timescales</a></b> with Niangjun Chen and Adam Wierman. CDC 2017. </li>
		</ol>   
         </td>
      </tr>
     

</table>
         
</body>

